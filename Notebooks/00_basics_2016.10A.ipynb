{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadioML dataset - 2016.10A\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a synthetic dataset generated with GNU Radio.\n",
    "- Consists of 11 modulations (8 digital and 3 analog) - E.g. - `8PSK`, `QPSK`, etc. Along with varying SNR ratios.\n",
    "- [Source](https://www.deepsig.ai/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "plt.rcParams[\"figure.figsize\"] = (18,7)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pickled raw file\n",
    "path = \"/Volumes/DHIRAJ/B.Tech/Project-1/RML2016.10a_dict.pkl\"\n",
    "with open(path, 'rb') as pic_file:\n",
    "    data = pickle.load(pic_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset -\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is originally stored in a dictionary format with keys as (modulation, SNR value).\n",
      "Input Data shape: (1000, 2, 128)\n",
      "Total labels: 220\n",
      "Modulation Techniques: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n",
      "SNR values: [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "snr_vals, mod_classes = map(lambda j: sorted(list(set(map(lambda x: x[j], data.keys())))), [1,0])\n",
    "print(\"Data is originally stored in a dictionary format with keys as (modulation, SNR value).\")\n",
    "print(f\"Input Data shape: {data[('QAM16', 18)].shape}\")\n",
    "print(f\"Total labels: {len(data.keys())}\")\n",
    "print(f\"Modulation Techniques: {mod_classes}\")\n",
    "print(f\"SNR values: {snr_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different signal representations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(samples, mod_name, SNR, plot_type=\"iq\"):\n",
    "    I_values = samples[0]\n",
    "    Q_values = samples[1]\n",
    "    signal = I_values + 1j * Q_values\n",
    "    if plot_type == \"iq\":\n",
    "        plt.plot(I_values, label=\"I values\", c='r', linewidth=3, alpha=0.75)\n",
    "        plt.plot(Q_values, label=\"Q values\", linewidth=3, alpha=0.75)\n",
    "        plt.plot(np.abs(signal), label=\"Amplitude\", c='b', linewidth=4, alpha=0.85)\n",
    "        plt.title(f\"IQ/Amplitude Vs Time{mod_name}-{str(SNR)}\")\n",
    "        plt.xlabel(\"Time in $\\mu s$\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if plot_type == \"ph_amp\":\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.suptitle(f\"Amplitude and Phase Vs Time ({mod_name}-{str(SNR)})\")\n",
    "        plt.plot(np.abs(signal), label=\"Amplitude\", c='b', linewidth=3, alpha=0.75)\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(np.angle(signal), label=\"Phase\", c='g', linewidth=3, alpha=0.75)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if plot_type == \"spec\":\n",
    "        spec = plt.specgram(signal,  Fs=1000, mode='magnitude')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"{mod_name}-{str(SNR)}\")\n",
    "        plt.show()\n",
    "# d = plt.magnitude_spectrum(c, Fs=1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(data[(\"QPSK\", 10)][0], \"QPSK\", 10, \"iq\")\n",
    "# plot_data(data[(\"QPSK\", 10)][0], \"QPSK\", 10, \"ph_amp\")\n",
    "# plot_data(data[(\"QPSK\", 10)][0], \"QPSK\", 10, \"spec\")\n",
    "# plot_data(data[(\"AM-SSB\", 10)][0], \"AM-SSB\", 10, \"iq\")\n",
    "# plot_data(data[(\"AM-SSB\", 10)][0], \"AM-SSB\", 10, \"ph_amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex = data[(\"QAM16\", 18)][0]\n",
    "# i = ex[0]\n",
    "# q = ex[1]\n",
    "# c = i + 1j * q\n",
    "# s = plt.specgram(c,  Fs=1000000, mode='psd')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.plot(s[1], s[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[('BPSK',  4)][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "---\n",
    "Steps -\n",
    "\n",
    "1. Remove the analog modulation techniques.\n",
    "2. Separate the training and testing data - Using `70%` (700/1000) for training and `30%` for testing.\n",
    "3. Create appropriate labels for the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total digital (mods, SNR) pairs (labels): 140\n",
      "Digital Mods: ['8PSK', 'AM-DSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QPSK']\n"
     ]
    }
   ],
   "source": [
    "analog_mods = ['AM-SSB', 'WBFM', 'QAM16', 'QAM64']\n",
    "removed_keys = [key for key in data if key[0] in analog_mods]\n",
    "digital_data = {key: data[key] for key in data if key not in removed_keys}\n",
    "digital_snrs, digital_mods = map(lambda j: sorted(list(set(map(lambda x: x[j], digital_data.keys())))), [1,0])\n",
    "print(f\"Total digital (mods, SNR) pairs (labels): {len(digital_data.keys())}\")\n",
    "print(f\"Digital Mods: {digital_mods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimensions: (600, 2, 128)\n",
      "Testing set dimensions: (400, 2, 128)\n"
     ]
    }
   ],
   "source": [
    "train_test_ratio = 0.6\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "for key, value in digital_data.items():\n",
    "    train_dict.update({key: value[:int(value.shape[0] * train_test_ratio), :]})\n",
    "    test_dict.update({key: value[int(value.shape[0] * train_test_ratio):, :]})\n",
    "print(f\"Training set dimensions: {train_dict[('8PSK',2)].shape}\")\n",
    "print(f\"Testing set dimensions: {test_dict[('8PSK',2)].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snrs, train_mods = map(lambda j: sorted(list(set(map(lambda x: x[j], train_dict.keys())))), [1,0])\n",
    "X_train = []  \n",
    "train_labels = []\n",
    "for mod in train_mods:\n",
    "    for snr in train_snrs:\n",
    "        X_train.append(train_dict[(mod, snr)])\n",
    "        for sample_number in range(train_dict[(mod,snr)].shape[0]):\n",
    "            train_labels.append((mod,snr))\n",
    "X_train = np.vstack(X_train)\n",
    "n_samples_train, dim1, dim2 = X_train.shape \n",
    "y_train = np.array(list(map(lambda x: train_mods.index(train_labels[x][0]), range(n_samples_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800,)\n"
     ]
    }
   ],
   "source": [
    "test_data = defaultdict(list)\n",
    "test_labels = defaultdict(list)\n",
    "def get_test_data_snr(snr):\n",
    "    for key, val in test_dict.items():\n",
    "        if key[1] == snr:\n",
    "            test_data[snr].append(val)\n",
    "            for x in range(val.shape[0]):\n",
    "                # For every sample with that SNR value\n",
    "                test_labels[snr].append(key[0]) # Save the mod name\n",
    "    test_data[snr] = np.vstack(test_data[snr])\n",
    "    n_samples_test = test_data[snr].shape[0]\n",
    "    test_labels[snr] = np.array(list(map(lambda x: train_mods.index(test_labels[snr][x]), range(n_samples_test))))\n",
    "    return test_data[snr], test_labels[snr]\n",
    "\n",
    "X_test = defaultdict(list)\n",
    "y_test = defaultdict(list)\n",
    "for snr in train_snrs:\n",
    "    data, labels = get_test_data_snr(snr)\n",
    "    X_test[snr].append(data)\n",
    "    X_test[snr] = np.vstack(X_test[snr])\n",
    "    y_test[snr].append(labels)\n",
    "    y_test[snr] = np.hstack(y_test[snr])\n",
    "print(y_test[-20].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_deviation(A, B, count):\n",
    "    sigma = np.power(A/count - np.power(B/count, 2), 0.5)\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    FS = 1000 # 1000kHz\n",
    "    FC = 45 # 45kHz\n",
    "    features = np.zeros([len(X), 8]) # Start with 8 features\n",
    "    for ex_no in range(X.shape[0]):\n",
    "        real_I = X[ex_no][0]\n",
    "        imag_Q = X[ex_no][1]\n",
    "        index_record = np.array([], dtype=int) # To hold the index for > threshold\n",
    "        signal = real_I + imag_Q * 1j # Construct the signal\n",
    "        total_frames = len(signal)\n",
    "        # Amplitude computations\n",
    "        A_i = np.power(np.power(real_I, 2) + np.power(imag_Q, 2), 0.5)\n",
    "        A_n = A_i / np.mean(A_i)\n",
    "        A_cn = A_n - 1\n",
    "        # Phase computations\n",
    "        threshold_a_cn = np.zeros(total_frames)\n",
    "        phase = np.angle(signal)\n",
    "        phi_unwrap = np.unwrap(phase)\n",
    "        phi_NL = np.zeros(total_frames)\n",
    "        # Subtract the linear part of the phase.\n",
    "        for i in range(total_frames):\n",
    "            if A_n[i] > 1:\n",
    "                phi_NL[i] = phi_unwrap[i] - (2 * np.pi * FC * i / FS)\n",
    "                index_record = np.append(index_record, i)\n",
    "                threshold_a_cn[i] = A_cn[i]\n",
    "            \n",
    "        phase_squared = np.sum(np.power(phi_NL, 2))\n",
    "        phase_abs = np.sum(np.abs(phi_NL))\n",
    "        phase_sum = np.sum(phi_NL)\n",
    "        thresh_acn_squared = np.sum(np.power(threshold_a_cn, 2))\n",
    "        thresh_acn_sum = np.sum(threshold_a_cn)\n",
    "        FN = np.zeros(len(index_record)-1)\n",
    "\n",
    "        # Frequency computations\n",
    "        for index, thresh_index in enumerate(index_record):\n",
    "            if index < len(index_record)-1:\n",
    "                FN[index] = (phi_NL[index_record[index+1]] - phi_NL[thresh_index]) / (2*np.pi)\n",
    "        Fn_squared = np.sum(np.power(FN, 2))\n",
    "        Fn_abs = np.sum(np.abs(FN))\n",
    "        \n",
    "        # Statistical features\n",
    "        deviations = signal - np.mean(signal)\n",
    "\n",
    "        #### Compute the features one by one\n",
    "        \"\"\" 1. Max value of power spectral density (PSD). Represents the variations in Amp,\n",
    "        differentiate between Amp and non-amp modulations.\n",
    "        \"\"\"\n",
    "        gamma_max = np.max(np.power(np.abs(np.fft.fft(A_cn)), 2)) / total_frames\n",
    "        sigma_aa = np.power(np.mean(np.power(A_cn, 2)) - np.power(np.mean(np.abs(A_cn)),2), 0.5)\n",
    "        sigma_ap = compute_standard_deviation(phase_squared, phase_abs, len(index_record))\n",
    "        sigma_dp = compute_standard_deviation(phase_squared, phase_sum, len(index_record))\n",
    "        sigma_a = compute_standard_deviation(thresh_acn_squared, thresh_acn_sum, len(index_record))\n",
    "        sigma_nf = compute_standard_deviation(Fn_squared, Fn_abs, len(index_record))\n",
    "        Kurtosis = np.abs(np.mean(np.power(deviations, 4)) / np.power(np.mean(np.power(deviations, 2)), 2))\n",
    "        Skewness = np.abs(np.mean(np.power(deviations, 3)) / np.power(np.mean(np.power(deviations, 2)), 1.5))\n",
    "        \n",
    "        #### Store the features\n",
    "        features[ex_no][0] = gamma_max\n",
    "        features[ex_no][1] = sigma_ap\n",
    "        features[ex_no][2] = sigma_dp\n",
    "        features[ex_no][3] = sigma_aa\n",
    "        features[ex_no][4] = sigma_a\n",
    "        features[ex_no][5] = sigma_nf\n",
    "        features[ex_no][6] = Kurtosis\n",
    "        features[ex_no][7] = Skewness\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = extract_features(X_train) # Send 10 examples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features1 = extract_features(X_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.338\n"
     ]
    }
   ],
   "source": [
    "for snr in [-10,-2,2,4,10]:\n",
    "    X_test_features = extract_features(X_test[snr])\n",
    "    pred = svm.predict(X_test_features)\n",
    "    acc = accuracy_score(y_test[snr], pred)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {-20: array([5, 5, 5, ..., 2, 2, 2]),\n",
       "             -18: array([2, 2, 2, ..., 1, 1, 1]),\n",
       "             -16: array([1, 1, 1, ..., 2, 2, 2]),\n",
       "             -14: array([0, 0, 0, ..., 2, 2, 2]),\n",
       "             -12: array([0, 0, 0, ..., 4, 4, 4]),\n",
       "             -10: array([1, 1, 1, ..., 5, 5, 5]),\n",
       "             -8: array([2, 2, 2, ..., 3, 3, 3]),\n",
       "             -6: array([4, 4, 4, ..., 0, 0, 0]),\n",
       "             -4: array([3, 3, 3, ..., 5, 5, 5]),\n",
       "             -2: array([1, 1, 1, ..., 0, 0, 0]),\n",
       "             0: array([2, 2, 2, ..., 5, 5, 5]),\n",
       "             2: array([5, 5, 5, ..., 4, 4, 4]),\n",
       "             4: array([1, 1, 1, ..., 2, 2, 2]),\n",
       "             6: array([3, 3, 3, ..., 0, 0, 0]),\n",
       "             8: array([4, 4, 4, ..., 3, 3, 3]),\n",
       "             10: array([2, 2, 2, ..., 5, 5, 5]),\n",
       "             12: array([0, 0, 0, ..., 4, 4, 4]),\n",
       "             14: array([4, 4, 4, ..., 2, 2, 2]),\n",
       "             16: array([1, 1, 1, ..., 3, 3, 3]),\n",
       "             18: array([3, 3, 3, ..., 5, 5, 5])})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys_list = list(data.keys())\n",
    "# temp_list = []\n",
    "# label_list = []\n",
    "# for i in range(len(keys_list)):\n",
    "#     curr_item = data[keys_list[i]] \n",
    "#     temp_list.append(curr_item)\n",
    "#     for j in range(curr_item.shape[0]):\n",
    "#         label_list.append(keys_list[i])\n",
    "        \n",
    "# # Convert all lists into numpy arrays.\n",
    "# # X = np.array(temp_list).reshape(1200000,2,128)\n",
    "# # Y = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], data.keys())))), [1,0])\n",
    "# X_train = []  \n",
    "# labels_train = []\n",
    "# for mod in mods:\n",
    "#     for snr in snrs:\n",
    "#         X_train.append(data[(mod,snr)])\n",
    "#         for i in range(data[(mod,snr)].shape[0]): \n",
    "#             labels_train.append((mod,snr))\n",
    "# X_train = np.vstack(X_train)\n",
    "# n_samples_train = X_train.shape[0]\n",
    "# y_train = np.array(list(map(lambda x: mods.index(labels_train[x][0]), range(n_samples_train))))\n",
    "\n",
    "# print(\"**Training data (raw data)**\")\n",
    "# print(X_train.shape,\"training data, \", y_train.shape, \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
